# -*- coding: utf-8 -*-
"""Heart Attack Prediction (SVM-Kernel).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OAuzir-m3TsUIAiKxZcc7Cyawc2-wLcf
"""

import numpy as np
import pandas as pd

"""## **Data Visualization**"""

heart = pd.read_csv('/content/heart.csv')
heart.head()

heart.shape

heart.isnull().sum()

heart.info()

heart[heart.duplicated()]

heart.drop_duplicates(keep='first', inplace=True)

heart.shape

heart.describe()

heart.corr()

"""## **Data Preprocessing**"""

x = heart.iloc[:, 1:-1].values
y = heart.iloc[:, -1].values
x,y

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state= 0)

print('Shape for training data', x_train.shape, y_train.shape)
print('Shape for testing data', x_test.shape, y_test.shape)

"""####**Feature Scaling**"""

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

"""#### **1.Logistic Regression**"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

model = LogisticRegression()
model.fit(x_train, y_train)
predicted=model.predict(x_test)
conf = confusion_matrix(y_test, predicted)
print ("Confusion Matrix : \n", conf)
print()
print()
print ("The accuracy of Logistic Regression is : ", accuracy_score(y_test, predicted)*100, "%")

"""####**2.Gaussian Naive Bayes**"""

from sklearn.naive_bayes import GaussianNB

model = GaussianNB()
model.fit(x_train, y_train)

predicted = model.predict(x_test)

print("The accuracy of Gaussian Naive Bayes model is : ", accuracy_score(y_test, predicted)*100, "%")

"""#### **3.Bernoulli Naive Bayes**"""

from sklearn.naive_bayes import BernoulliNB

model = BernoulliNB()
model.fit(x_train, y_train)

predicted = model.predict(x_test)

print("The accuracy of Gaussian Naive Bayes model is : ", accuracy_score(y_test, predicted)*100, "%")

"""#### **4.Support Vector Machine**"""

from sklearn.svm import SVC

model = SVC(kernel="rbf")
model.fit(x_train, y_train)

predicted = model.predict(x_test)
print("The accuracy of SVM is : ", accuracy_score(y_test, predicted)*100, "%")

"""##### **Polynomial Kernel**"""

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Define the custom polynomial kernel

def polynomial_kernel(X, Y, degree=2, gamma=0.1, coef0=2):
    # Compute the dot product between X and Y.
    K = np.dot(X, Y.T)

    # Apply the polynomial kernel function.
    K = (gamma * K + coef0)**degree

    return K


# Define the SVC model with the custom polynomial kernel
svc = SVC(kernel=polynomial_kernel)

# Fit the model on the training set
svc.fit(x_train, y_train)

# Make predictions on the test set
y_pred = svc.predict(x_test)

# Compute the accuracy of the model
acc = accuracy_score(y_test, y_pred)
print("Accuracy (Polynomial kernel) :", acc*100,'%')

"""##### **Exponential Kernel**"""

# Define the custom exponential kernel

def exponential_kernel(X1, X2, sigma=2):
    m = X1.shape[0]
    p = X2.shape[0]
    K = np.zeros((m, p))

    for i in range(m):
        for j in range(p):
            diff = X1[i, :] - X2[j, :]
            K[i, j] = np.exp(-np.dot(diff, diff) / (2 * sigma**2))

    return K


# Define the SVC model with the custom exponential kernel
svc = SVC(kernel=exponential_kernel)

# Fit the model on the training set
svc.fit(x_train, y_train)

# Make predictions on the test set
y_pred = svc.predict(x_test)

# Compute the accuracy of the model
acc = accuracy_score(y_test, y_pred)
print("Accuracy (Exponential kernel) :", acc*100,'%')

"""##### **Laplacian Kernel**"""

from sklearn.metrics import recall_score
from sklearn.metrics import f1_score

# Define the custom laplacian kernel

def laplacian_kernel(X1, X2, gamma=1.0):
    n_samples1 = X1.shape[0]
    n_samples2 = X2.shape[0]
    kernel_matrix = np.zeros((n_samples1, n_samples2))

    for i in range(n_samples1):
        for j in range(n_samples2):
            norm = np.linalg.norm(X1[i] - X2[j])
            kernel_matrix[i, j] = np.exp(-gamma * norm)

    return kernel_matrix


# Define the SVC model with the custom laplacian kernel
svc = SVC(kernel=laplacian_kernel)

# Fit the model on the training set
svc.fit(x_train, y_train)

# Make predictions on the test set
y_pred = svc.predict(x_test)


# Compute the accuracy of the model
acc = accuracy_score(y_test, y_pred)
print("Accuracy (laplacian kernel) :", acc*100,'%')

# Compute the Recall score of the model
recall = recall_score(y_test, y_pred)
print("Recall score: {:.5f}".format(recall))

# Calculate F1 score
f1 = f1_score(y_test, y_pred)
print("F1 score:", f1)

# Compute the Confusion Matrix of the model
cm = confusion_matrix(y_test, y_pred)
print("Confusion matrix : \n",cm)

